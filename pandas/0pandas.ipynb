{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6937f54",
   "metadata": {},
   "source": [
    "# --- Start of `First` notebook ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b60f3",
   "metadata": {},
   "source": [
    "# VERY_IMP ek bho code yaha nehi chalta , pata nehi iska conda ka kya issue hai , better copy paste in your khud ka alag python file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46aa80",
   "metadata": {},
   "source": [
    "# What is Data Manipulation and Analysis?\n",
    "\n",
    "## Data Manipulation\n",
    "    Definition: Changing, organizing, or preparing data to make it useful and easier to understand.\n",
    "    Goal: To clean, transform, and structure raw data for better usability.\n",
    "    Example:\n",
    "    -> Organizing a Grocery List: Sorting random items into categories like \"Fruits\" or \"Dairy\".\n",
    "    -> Fixing Errors in a Student Record: Correcting missing or wrong grades.\n",
    "\n",
    "## Data Analysis\n",
    "    Definition: Extracting patterns, trends, and insights from the data to solve problems or make informed decisions.\n",
    "    Goal: To answer questions or identify trends using the data.\n",
    "    Example:\n",
    "    -> Analyzing Sales Trends: Finding the month with the highest revenue.\n",
    "    -> Tracking Fitness Progress: Analyzing daily steps and calories for activity patterns and improvements over time.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0895f0df",
   "metadata": {},
   "source": [
    "  # Key Differences Between Data Manipulation and Analysis:\n",
    "\n",
    " | Aspect      | Data Manipulation                        | Data Analysis                              |\n",
    "| ----------- | ---------------------------------------- | ------------------------------------------ |\n",
    "| **Focus**   | Preparing and cleaning data              | Extracting insights from prepared data     |\n",
    "| **Goal**    | Organize and structure raw data          | Find patterns, trends, and solve problems  |\n",
    "| **Example** | Fixing errors in a student's grade sheet | Analyzing which student scored the highest |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0c141e",
   "metadata": {},
   "source": [
    "### **What is Pandas?**\n",
    "\n",
    "**Pandas** is a powerful and widely-used **Python library** designed for:\n",
    "\n",
    "* **Data Manipulation**: Cleaning, transforming, and structuring data.\n",
    "* **Data Analysis**: Identifying patterns, trends, and extracting insights.\n",
    "\n",
    "It simplifies working with **structured datasets** such as:\n",
    "\n",
    "* Tables\n",
    "* Spreadsheets\n",
    "* Time-series data\n",
    "\n",
    "With Pandas, tasks like filtering, grouping, merging, and summarizing data become much easier and more efficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c0164",
   "metadata": {},
   "source": [
    "### **What Makes Pandas Unique?**\n",
    "\n",
    "**Key Features:**\n",
    "a. Works seamlessly with structured data formats like CSV and Excel.\n",
    "\n",
    "b. Handles missing values easily.\n",
    "\n",
    "c. Built on NumPy for fast computations.\n",
    "### **Why Use Pandas?**\n",
    "\n",
    "**a. Performance:** Handles millions of rows efficiently.\n",
    "\n",
    "**b. Ease of Use:** Beginner-friendly syntax for cleaning and transforming data.\n",
    "\n",
    "**c. Integration:** Works with libraries like Matplotlib (for visualizations) and Scikit-learn (for machine learning).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c07e79",
   "metadata": {},
   "source": [
    "## Real-Life Examples of Pandas in Action\n",
    "**Finance:**\n",
    "Analyzing time-series data like stock prices to identify market trends.\n",
    "\n",
    "**Retail:**\n",
    "Tracking inventory and finding the most sold products in a store.\n",
    "\n",
    "**Healthcare:**\n",
    "Analyzing patient records and outcomes from clinical trials.\n",
    "\n",
    "**Education:**\n",
    "Evaluating student performance across subjects to improve teaching strategies.\n",
    "\n",
    "**Sports:**\n",
    "Analyzing player statistics to make strategic decisions for upcoming games.\n",
    "\n",
    "**Transportation:**\n",
    "Monitoring vehicle GPS data to optimize delivery routes and reduce fuel costs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d671c0e7",
   "metadata": {},
   "source": [
    "## Key Pandas Concepts\n",
    "**Series:**\n",
    "A Series is a one-dimensional labeled array that can hold any data type: integers, floats, strings, or even Python objects. Each element in the Series has a unique label called an index.\n",
    "It is often used to track changes or patterns over time, such as daily temperatures, stock prices, or sales revenue.\n",
    "\n",
    "**DataFrame:**\n",
    "A DataFrame is a two-dimensional labeled data structure with columns of potentially different types. It‚Äôs like a spreadsheet or SQL table.\n",
    "DataFrames are commonly used to store datasets, such as customer information, product catalogs, or survey results.\n",
    "\n",
    "**Index:**\n",
    "An Index is used to label and align data in Series or DataFrames.\n",
    "It allows for fast lookups, selection, and alignment of data during operations like merging, joining, or slicing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51801445",
   "metadata": {},
   "source": [
    "**DataFrame:**\n",
    "A DataFrame is a two-dimensional labeled data structure in Pandas, similar to a table in a database, an Excel spreadsheet, or a SQL table.\n",
    "It consists of rows and columns, where:\n",
    "\n",
    "a. Rows have indices (labels).\n",
    "\n",
    "b. Columns have names (labels).\n",
    "\n",
    "c. Each column can contain data of different types (e.g., integer, float, string).\n",
    "\n",
    "d. It allows for easy data manipulation, filtering, and analysis using built-in Pandas functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a6208d",
   "metadata": {},
   "source": [
    "### Basically ,*Series* is 1D and *DataFrame* is 2D "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2810e0b",
   "metadata": {},
   "source": [
    "# Reading files in pandas\n",
    "note , create a *\".py\"* file and perform all \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4227e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                                               name  \\\n",
      "0    1                                    Apple iPhone 12   \n",
      "1    2                                 Samsung Galaxy S21   \n",
      "2    3                                 Sony PlayStation 5   \n",
      "3    4                  LG OLED55CXPUA 55-inch 4K OLED TV   \n",
      "4    5        Bose QuietComfort 35 II Wireless Headphones   \n",
      "5    6                          Fitbit Versa 3 Smartwatch   \n",
      "6    7                             KitchenAid Stand Mixer   \n",
      "7    8                 Dyson V11 Absolute Cordless Vacuum   \n",
      "8    9                         Ninja Foodi Smart XL Grill   \n",
      "9   10                    Canon EOS Rebel T8i DSLR Camera   \n",
      "10  11                                  Apple AirPods Pro   \n",
      "11  12        Bose QuietComfort 35 II Wireless Headphones   \n",
      "12  13                    Fitbit Charge 4 Fitness Tracker   \n",
      "13  14                              Samsung Galaxy Watch3   \n",
      "14  15  Sony WH-1000XM4 Wireless Noise-Cancelling Head...   \n",
      "15  16          Breville Barista Express Espresso Machine   \n",
      "16  17                        Keurig K-Elite Coffee Maker   \n",
      "17  18                     iRobot Roomba i7+ Robot Vacuum   \n",
      "18  19                   Ninja Foodi Digital Air Fry Oven   \n",
      "19  20                   Cuisinart ICE-70 Ice Cream Maker   \n",
      "\n",
      "                                          description    price  \\\n",
      "0   The Apple iPhone 12 features a 6.1-inch Super ...   999.00   \n",
      "1   The Samsung Galaxy S21 features a 6.2-inch Dyn...   799.00   \n",
      "2   The Sony PlayStation 5 features an AMD Zen 2-b...   499.99   \n",
      "3   The LG OLED55CXPUA 55-inch 4K OLED TV features...  1599.99   \n",
      "4   The Bose QuietComfort 35 II Wireless Headphone...   299.00   \n",
      "5   The Fitbit Versa 3 Smartwatch features a built...   229.95   \n",
      "6   The KitchenAid Stand Mixer features a 5-quart ...   399.99   \n",
      "7   The Dyson V11 Absolute Cordless Vacuum feature...   699.99   \n",
      "8   The Ninja Foodi Smart XL Grill features 6-in-1...   279.99   \n",
      "9   The Canon EOS Rebel T8i DSLR Camera features a...   899.00   \n",
      "10  The Apple AirPods Pro feature active noise can...   249.00   \n",
      "11  The Bose QuietComfort 35 II Wireless Headphone...   299.00   \n",
      "12  The Fitbit Charge 4 Fitness Tracker features G...   129.95   \n",
      "13  The Samsung Galaxy Watch3 features a rotating ...   399.99   \n",
      "14  The Sony WH-1000XM4 Wireless Noise-Cancelling ...   349.99   \n",
      "15  The Breville Barista Express Espresso Machine ...   699.95   \n",
      "16  The Keurig K-Elite Coffee Maker features a str...   169.99   \n",
      "17  The iRobot Roomba i7+ Robot Vacuum features au...   799.99   \n",
      "18  The Ninja Foodi Digital Air Fry Oven features ...   209.99   \n",
      "19  The Cuisinart ICE-70 Ice Cream Maker features ...   139.99   \n",
      "\n",
      "           category                                              image  \n",
      "0       Electronics  https://www.apple.com/newsroom/images/product/...  \n",
      "1       Electronics  https://images.samsung.com/is/image/samsung/p6...  \n",
      "2       Electronics  https://www.sony.com/image/44baa604124b770c824...  \n",
      "3       Electronics  https://www.lg.com/us/images/tvs/md07501804/ga...  \n",
      "4       Electronics  https://assets.bose.com/content/dam/Bose_DAM/W...  \n",
      "5       Electronics  https://www.fitbit.com/global/content/dam/fitb...  \n",
      "6    Home & Kitchen  https://www.kitchenaid.com/content/dam/global/...  \n",
      "7   Home Appliances  https://www.dysoncanada.ca/dam/dyson/images/pr...  \n",
      "8    Home & Kitchen  https://www.ninjakitchen.com/medias/Ninja-OP50...  \n",
      "9       Electronics  https://www.canon.com.au/-/media/images/produc...  \n",
      "10      Electronics  https://www.apple.com/v/airpods-pro/b/images/m...  \n",
      "11      Electronics  https://assets.bose.com/content/dam/Bose_DAM/W...  \n",
      "12      Electronics  https://www.fitbit.com/global/content/dam/fitb...  \n",
      "13      Electronics  https://images.samsung.com/is/image/samsung/as...  \n",
      "14      Electronics  https://www.sony.com/image/1cdd6354c4cd21cc4f7...  \n",
      "15   Home & Kitchen  https://www.breville.com/content/dam/breville/...  \n",
      "16   Home & Kitchen  https://www.keurig.com/content/dam/global-ecom...  \n",
      "17   Home & Kitchen  https://store.irobot.com/default/i7-vacuuming-...  \n",
      "18   Home & Kitchen  https://www.ninjakitchen.com/static/img/produc...  \n",
      "19   Home & Kitchen  https://www.cuisinart.com/share/images/product...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# # to read a csv file\n",
    "# df=pd.read_csv(\"pract\\sales_data_sample.csv\",encoding=\"latin1\") #df= var name for DATAFRAME\n",
    "\n",
    "# # to read excel file\n",
    "# df = pd.read_excel(\"pract\\SampleSuperstore.xlsx\")\n",
    "\n",
    "# # to read json file\n",
    "df=pd.read_json(r\"C:\\Users\\wwwsh\\OneDrive\\Desktop\\proj_1\\data_sci\\pract\\sample_Data.json\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1734a6",
   "metadata": {},
   "source": [
    "## *Encoding* ke hai 2 jaat -> jab file na khule , tab kare prayog\n",
    "(1) \"filepath\",encoding=\"latin1\"\n",
    "\n",
    "(2) \"filepath\",encoding=\"utf-8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da8ab1",
   "metadata": {},
   "source": [
    "# üìÇ Creating and Saving Files using Pandas\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "- Create a DataFrame using `pandas`\n",
    "- Save it into **CSV**, **Excel (XLSX)**, and **JSON** formats\n",
    "- Learn basic syntax for file-saving options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0fb8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÉ Step 1: Import required library\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280deb6",
   "metadata": {},
   "source": [
    "## üìã Step 2: Create a DataFrame\n",
    "\n",
    "Let's create a sample dataset of names, ages, and cities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ce68e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age        City\n",
      "0  Shaunak   10    Shillong\n",
      "1  Sarthak   20     Silchar\n",
      "2    Ronit   30  Hailakandi\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = {\n",
    "    \"Name\": ['Shaunak', 'Sarthak', 'Ronit'],\n",
    "    \"Age\": [10, 20, 30],\n",
    "    \"City\": ['Shillong', 'Silchar', 'Hailakandi']\n",
    "}\n",
    "\n",
    "# Creating DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f67dabd",
   "metadata": {},
   "source": [
    "## üíæ Step 3: Save the DataFrame to Multiple Formats\n",
    "\n",
    "We'll save the above DataFrame into:\n",
    "- **CSV** file using `to_csv()`\n",
    "- **Excel (XLSX)** file using `to_excel()`\n",
    "- **JSON** file using `to_json()`\n",
    "\n",
    "All files will be saved inside the folder `pract/`. Make sure this folder exists or create it using `os.makedirs(\"pract\", exist_ok=True)` before saving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cabd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAFETY, chatgpt karlo to understand better\n",
    "import os\n",
    "os.makedirs(\"saving\", exist_ok=True)\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv(\"saving/pratham.csv\", index=False)\n",
    "\n",
    "# Save as Excel\n",
    "df.to_excel(\"saving/pratham.xlsx\", index=False)\n",
    "\n",
    "# Save as JSON\n",
    "df.to_json(\"saving/pratham.json\", orient='records', lines=False)\n",
    "\n",
    "print(\"‚úÖ All files saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9545ec",
   "metadata": {},
   "source": [
    "# agey kam kam , dusre notebook mey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb456a28",
   "metadata": {},
   "source": [
    "# --- End of `First` notebook ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa220c",
   "metadata": {},
   "source": [
    "# --- Start of `Second` notebook ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa9787d",
   "metadata": {},
   "source": [
    "# üìä Dataset Exploration: Understand, Identify Problems & Plan Next Steps\n",
    "\n",
    "In this notebook, we'll perform basic data exploration using a JSON dataset. The process includes:\n",
    "\n",
    "1. ‚úÖ Understanding the dataset  \n",
    "2. ‚ùó Identifying potential problems  \n",
    "3. üìå Planning next steps\n",
    "\n",
    "We'll also explore:\n",
    "- Viewing rows using `head()` and `tail()`\n",
    "- Checking data types\n",
    "- Counting missing values\n",
    "- Checking memory usage and structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ae238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÉ Step 1: Importing required library\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff5c58",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Load the Dataset\n",
    "\n",
    "We are loading a JSON dataset located at `pract/sample_Data.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8826db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Load JSON file into DataFrame\n",
    "df = pd.read_json(\"pract/sample_Data.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87bf80",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 3: Understand the Dataset\n",
    "\n",
    "We will:\n",
    "- View top and bottom rows\n",
    "- Check dimensions\n",
    "- View column names\n",
    "- Get info about data types and memory usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Show first 7 rows (initial inspection)\n",
    "print(\"üîπ Pehle 7 rows:\")\n",
    "print(df.head(7))  # head(n): Returns first n rows\n",
    "\n",
    "# üìå Show last 7 rows\n",
    "print(\"\\nüîπ Last ke 7 rows:\")\n",
    "print(df.tail(7))  # tail(n): Returns last n rows\n",
    "\n",
    "# üìå Default head() and tail(): first & last 5 rows\n",
    "print(\"\\nüîπ Starting ke 5 rows (default head):\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nüîπ Ending ke 5 rows (default tail):\")\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945998c7",
   "metadata": {},
   "source": [
    "## ‚ùó Step 4: Identify Potential Problems\n",
    "\n",
    "We will:\n",
    "- Check number of rows and columns\n",
    "- Identify column names\n",
    "- Look at data types\n",
    "- Find missing (null) values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¢ Data types, non-null values, memory usage\n",
    "print(\"\\n‚ÑπÔ∏è DataFrame Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055fb204",
   "metadata": {},
   "source": [
    "# 5 galti sey chut gaya \n",
    "## üìà Step 6: Summary Statistics using `describe()`\n",
    "\n",
    "The `describe()` method gives us basic statistical info for all **numerical columns**, such as:\n",
    "\n",
    "- `count`: Number of non-null entries  \n",
    "- `mean`: Average value  \n",
    "- `std`: Standard deviation (spread) -> jitna kam std utna zyada consistent data  \n",
    "- `min`, `max`: Minimum and maximum values  \n",
    "- `25%`, `50%`, `75%`: Percentiles (useful to understand distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2873f8db",
   "metadata": {},
   "source": [
    "# VVIMP\n",
    "# üß† What do 25%, 50%, and 75% mean?\n",
    "\n",
    "They are **percentiles** (also called quartiles) that **help describe the spread/distribution of your data**.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Think of your data as a sorted list of numbers.\n",
    "\n",
    "Suppose you have a sorted list of ages: \n",
    "[10, 12, 15, 18, 21, 24, 28, 30, 35, 40]\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ 25% ‚Üí First Quartile (Q1)\n",
    "\n",
    "- **Meaning**: 25% of the values are **less than or equal to this value**.\n",
    "- In our list: 25% point = 3rd value = **15**\n",
    "- So, 25% of people are aged **15 or younger**\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ 50% ‚Üí Second Quartile (Median)\n",
    "\n",
    "- **Meaning**: Half of the values (50%) are **less than or equal to this value**\n",
    "- This is also known as the **median**\n",
    "- In our list: Median = average of 5th and 6th values = (21+24)/2 = **22.5**\n",
    "- So, 50% of people are aged **22.5 or younger**\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ 75% ‚Üí Third Quartile (Q3)\n",
    "\n",
    "- **Meaning**: 75% of the values are **less than or equal to this value**\n",
    "- In our list: 75% point = 8th value = **30**\n",
    "- So, 75% of people are aged **30 or younger**\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ Visual Representation:\n",
    "|--------|--------|--------|--------|\n",
    " Min     25%      50%      75%     Max\n",
    "         Q1       Q2       Q3\n",
    "\n",
    "\n",
    "- This kind of division is also used in **boxplots** üì¶ to visualize spread and detect outliers.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Why it matters:\n",
    "\n",
    "These values help you understand:\n",
    "- If your data is **skewed** (leaning toward high or low values)\n",
    "- Whether there are **outliers** (values that are way too high or low)\n",
    "- How **spread out** your data is\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520fb62a",
   "metadata": {},
   "source": [
    "# üìä Employee Data Analysis using Pandas\n",
    "\n",
    "In this notebook, we'll:\n",
    "\n",
    "- Create a sample dataset of employees\n",
    "- Display the dataset\n",
    "- Use `.describe()` to get statistical insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b28aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÉ Step 1: Import pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091587fe",
   "metadata": {},
   "source": [
    "## üßæ Step 2: Create the Dataset\n",
    "\n",
    "We are creating a simple dataset with the following columns:\n",
    "- Name\n",
    "- Age\n",
    "- Salary\n",
    "- Performance Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef50c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß± Creating sample employee data\n",
    "data = {\n",
    "    \"Name\": ['Ram', 'Shyam', 'Ghanshyam', 'Dhanshyam', 'Aditi', 'Jagdish','Raj', 'Simran'],\n",
    "    \"Age\" : [28, 32, 47, 57, 17, 27, 77, 25],\n",
    "    \"Salary\": [5000, 6000, 45000, 5200, 4900, 7000, 9000, 17000],\n",
    "    \"Performance Score\": [43, 71, 26, 59, 84, 38, 67, 22]  \n",
    "}\n",
    "\n",
    "# üìã Creating DataFrame from dictionary\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93107e43",
   "metadata": {},
   "source": [
    "## üîç Step 3: View the Created Dataset\n",
    "We'll print the full DataFrame to inspect our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945db4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the full dataset\n",
    "print(\"üìå Created Dataset:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc047a0f",
   "metadata": {},
   "source": [
    "## üìà Step 4: Statistical Summary using `.describe()`\n",
    "\n",
    "This function provides:\n",
    "- Count, mean, std deviation\n",
    "- Min, 25%, 50%, 75%, and max values\n",
    "for all numeric columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37786628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numeric columns\n",
    "print(\"\\nüìä Statistical Summary (describe):\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb79c8a",
   "metadata": {},
   "source": [
    "# baki kam agle notebook mey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6712cb",
   "metadata": {},
   "source": [
    "# --- End of `Second` notebook ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6be0ee",
   "metadata": {},
   "source": [
    "# --- Start of `Third` notebook ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a588a",
   "metadata": {},
   "source": [
    "# üìã Creating and Exploring a Basic DataFrame in Pandas\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "1. Create a simple DataFrame using Python dictionaries\n",
    "2. Understand the shape (rows √ó columns)\n",
    "3. List all column names\n",
    "4. Review initial structure and contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306bae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÉ Step 1: Import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27849639",
   "metadata": {},
   "source": [
    "## üß± Step 2: Define the dataset\n",
    "\n",
    "We are creating a dictionary with:\n",
    "- Name\n",
    "- Age\n",
    "- Salary\n",
    "- Performance Score\n",
    "\n",
    "We'll convert this into a pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fac42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample employee data\n",
    "data = {\n",
    "    \"Name\": ['Ram', 'Shyam', 'Ghanshyam', 'Dhanshyam', 'Aditi', 'Jagdish', 'Raj', 'Simran'],\n",
    "    \"Age\" : [28, 32, 47, 57, 17, 27, 77, 25],\n",
    "    \"Salary\": [5000, 6000, 45000, 5200, 4900, 7000, 9000, 17000],\n",
    "    \"Performance Score\": [43, 71, 26, 59, 84, 38, 67, 22]\n",
    "}\n",
    "\n",
    "# ‚úÖ Step 3: Create DataFrame from dictionary\n",
    "df = pd.DataFrame(data)\n",
    "print(\"üìÑ Employee Data:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1944c93",
   "metadata": {},
   "source": [
    "## üìê Step 4: Understand the structure\n",
    "\n",
    "We will now:\n",
    "- Print the shape (rows, columns)\n",
    "- Print column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a52e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßÆ Shape of the DataFrame ‚Äî like numpy array shape\n",
    "print(f\"\\nShape: {df.shape}\")  \n",
    "# Output: Shape: (8, 4) ‚Äî 8 rows, 4 columns\n",
    "\n",
    "# üè∑Ô∏è Column names ‚Äî shows the keys/fields used\n",
    "print(f\"Column Names: {df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e8a28b",
   "metadata": {},
   "source": [
    "  \n",
    "## ‚úçÔ∏è Notes:\n",
    "\n",
    "- `df.shape` ‚ûù Returns a tuple: **(number of rows, number of columns)**  \n",
    "  (Same concept as NumPy arrays ‚Äî check your earlier NumPy notes!)\n",
    "\n",
    "- `df.columns` ‚ûù Returns an Index object containing the column names  \n",
    "  Use `.tolist()` to get them as a regular Python list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e061c",
   "metadata": {},
   "source": [
    "# üéØ Selecting Specific Columns and Filtering Rows in Pandas\n",
    "\n",
    "In this notebook, we will learn:\n",
    "\n",
    "- How to select single or multiple columns\n",
    "- How to filter rows based on conditions\n",
    "- Boolean indexing techniques\n",
    "- Combining multiple conditions using `&` and `|`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a111004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÉ Step 1: Import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59225130",
   "metadata": {},
   "source": [
    "## üìã Step 2: Creating Sample DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ad7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Name\": ['Ram', 'Shyam', 'Ghanshyam', 'Dhanshyam', 'Aditi', 'Jagdish','Raj', 'Simran'],\n",
    "    \"Age\" : [28,32,47,57,17,27,77,25],\n",
    "    \"Salary\": [5000, 6000, 45000, 5200, 4900, 7000, 9000, 17000],\n",
    "    \"Performance Score\": [43, 71, 26, 59, 84, 38, 67, 22]  \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display full DataFrame\n",
    "print(df)\n",
    "\n",
    "# Display shape\n",
    "print(f\"\\nüìê Shape (Rows, Columns): {df.shape}\")  # Rows, Columns\n",
    "\n",
    "# Display column names\n",
    "print(f\"üìù Column Names: {df.columns.tolist()}\")  # List of column names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb8d4a0",
   "metadata": {},
   "source": [
    "## üîπ Select Specific Columns\n",
    "We can access specific columns using:\n",
    "\n",
    "- `df[\"column_name\"]` ‚Üí returns a **Series**\n",
    "- `df[[\"col1\", \"col2\"]]` ‚Üí returns a **DataFrame**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3afc64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßç Accessing a single column as Series\n",
    "nam = df[\"Name\"]\n",
    "print(\"üî∏ Single Column (Series):\\n\", nam)\n",
    "\n",
    "# üßë‚Äçü§ù‚Äçüßë Accessing multiple columns as DataFrame\n",
    "anek = df[[\"Name\", \"Age\"]]\n",
    "print(\"\\nüî∏ Multiple Columns (DataFrame):\\n\", anek)\n",
    "\n",
    "# üìå General syntax:\n",
    "# Single column:     df[\"column_name\"]\n",
    "# Multiple columns:  df[[\"col1\", \"col2\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a2c516",
   "metadata": {},
   "source": [
    "## üß™ Filtering Rows using Boolean Conditions\n",
    "\n",
    "We can filter rows using:\n",
    "\n",
    "- `df[df[\"column\"] > value]` ‚Üí single condition\n",
    "- `df[(df[\"col1\"] > val1) & (df[\"col2\"] < val2)]` ‚Üí AND condition\n",
    "- `df[(df[\"col1\"] > val1) | (df[\"col2\"] < val2)]` ‚Üí OR condition\n",
    "\n",
    "Make sure to use **parentheses** around each condition!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîé Filtering rows: Single condition\n",
    "print(\"\\nüîç Rows where Salary > 6000:\")\n",
    "shabji = df[df[\"Salary\"] > 6000]\n",
    "print(shabji)\n",
    "\n",
    "# üìå Syntax: df[df[\"column_name\"] > value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25171a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîé Filtering rows: Two conditions using \"&\"\"\n",
    "print(\"\\nüîç Rows where Salary > 6000 AND Age > 27:\")\n",
    "sahab = df[(df[\"Salary\"] > 6000) & (df[\"Age\"] > 27)]\n",
    "print(sahab)\n",
    "\n",
    "# üìå Syntax: df[(df[\"col1\"] > val1) & (df[\"col2\"] > val2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f3a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîé Filtering rows: Multiple conditions using |\n",
    "print(\"\\nüîç Rows where Salary > 6000 OR Performance Score > 43:\")\n",
    "bare_sahab = df[(df[\"Salary\"] > 6000) | (df[\"Performance Score\"] > 43)]\n",
    "print(bare_sahab)\n",
    "\n",
    "# üìå Syntax: df[(df[\"col1\"] > val1) | (df[\"col2\"] > val2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922fd604",
   "metadata": {},
   "source": [
    "## üß† Summary Notes (Cheat Sheet)\n",
    "\n",
    "- **Select single column (Series)**: `df[\"column_name\"]`\n",
    "- **Select multiple columns (DataFrame)**: `df[[\"col1\", \"col2\"]]`\n",
    "- **Filter rows - one condition**: `df[df[\"column\"] > value]`\n",
    "- **Filter rows - multiple conditions**:  \n",
    "  Use `&` for AND, `|` for OR, and wrap each condition in `()`\n",
    "\n",
    "‚úÖ Always use parentheses when combining conditions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d122b08",
   "metadata": {},
   "source": [
    "# --- End of `Third` notebook ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12bd4a6",
   "metadata": {},
   "source": [
    "# --- Start of `Fourth` notebook ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33398ed",
   "metadata": {},
   "source": [
    "# ‚ûï Adding New Columns in a DataFrame (Assignment & Insert)\n",
    "\n",
    "In this notebook, we'll learn how to add new columns to a pandas DataFrame in two ways:\n",
    "\n",
    "1. Using **assignment (`df[\"new_col\"] = values`)**\n",
    "2. Using **`df.insert(position_index, \"col_name\", values inside list \"[]\")`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba29118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÉ Step 1: Import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c6a29",
   "metadata": {},
   "source": [
    "## üìã Step 2: Create the Initial DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72470c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample employee data\n",
    "data = {\n",
    "    \"Name\": ['Ram', 'Shyam', 'Ghanshyam', 'Dhanshyam', 'Aditi', 'Jagdish', 'Raj', 'Simran'],\n",
    "    \"Age\" : [28, 32, 47, 57, 17, 27, 77, 25],\n",
    "    \"Salary\": [5000, 6000, 45000, 5200, 4900, 7000, 9000, 17000],\n",
    "    \"Performance Score\": [43, 71, 26, 59, 84, 38, 67, 22]  \n",
    "}\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a8a8d3",
   "metadata": {},
   "source": [
    "## üßæ Step 3: Add New Column using Assignment\n",
    "\n",
    "We will calculate **10% bonus** on salary and add it as a new column called `\"Bonus\"`.\n",
    "\n",
    "üìå Syntax:  \n",
    "```python\n",
    "df[\"new_col_name\"] = some_operation_on_existing_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e283ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Bonus column using assignment\n",
    "df[\"Bonus\"] = df[\"Salary\"] * (10 / 100)  # 10% of Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c5734b",
   "metadata": {},
   "source": [
    "## üßæ Step 4: Add New Column using `.insert()`\n",
    "\n",
    "We will add a new `\"Emp_ID\"` column at the beginning (position 0) using:\n",
    "\n",
    "üìå Syntax:\n",
    "```python\n",
    "df.insert(loc=0, column=\"Col_Name\", value=data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b3f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Emp_ID column at the first position\n",
    "df.insert(0, \"Emp_ID\", [10, 20, 30, 40, 50, 60, 70, 80])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2e5a16",
   "metadata": {},
   "source": [
    "## üìä Final DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26446922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Emp_ID       Name  Age  Salary  Performance Score   Bonus\n",
      "0      10        Ram   28    5000                 43   500.0\n",
      "1      20      Shyam   32    6000                 71   600.0\n",
      "2      30  Ghanshyam   47   45000                 26  4500.0\n",
      "3      40  Dhanshyam   57    5200                 59   520.0\n",
      "4      50      Aditi   17    4900                 84   490.0\n",
      "5      60    Jagdish   27    7000                 38   700.0\n",
      "6      70        Raj   77    9000                 67   900.0\n",
      "7      80     Simran   25   17000                 22  1700.0\n"
     ]
    }
   ],
   "source": [
    "# Showing the final DataFrame with all columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617a0d3",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Pandas Operations ‚Äì Update, Increase, Delete\n",
    "\n",
    "In this notebook, we will learn how to:\n",
    "\n",
    "- Update specific values in a DataFrame\n",
    "- Increase numerical column values (like Salary)\n",
    "- Delete or drop unwanted columns\n",
    "\n",
    "We'll also include general syntax notes for all these operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f60861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∞ Original DataFrame:\n",
      "\n",
      "        Name  Age  Salary  Performance Score\n",
      "0        Ram   28    5000                 43\n",
      "1      Shyam   32    6000                 71\n",
      "2  Ghanshyam   47   45000                 26\n",
      "3  Dhanshyam   57    5200                 59\n",
      "4      Aditi   17    4900                 84\n",
      "5    Jagdish   27    7000                 38\n",
      "6        Raj   77    9000                 67\n",
      "7     Simran   25   17000                 22\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import pandas and prepare sample data\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Name\": ['Ram', 'Shyam', 'Ghanshyam', 'Dhanshyam', 'Aditi', 'Jagdish', 'Raj', 'Simran'],\n",
    "    \"Age\" : [28, 32, 47, 57, 17, 27, 77, 25],\n",
    "    \"Salary\": [5000, 6000, 45000, 5200, 4900, 7000, 9000, 17000],\n",
    "    \"Performance Score\": [43, 71, 26, 59, 84, 38, 67, 22]  \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"üî∞ Original DataFrame:\\n\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cff356",
   "metadata": {},
   "source": [
    "## ‚úèÔ∏è Updating a Specific Cell using `.loc[]`\n",
    "\n",
    "We use `.loc[row_index, 'column_name'] = new_value` to update a specific value.\n",
    "\n",
    "Let's update **Shyam's salary** from 6000 to 6900.\n",
    "\n",
    "### üìå Syntax:\n",
    "```python\n",
    "df.loc[row_index, 'column_name'] = new_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac9e6a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Updated Salary of Shyam:\n",
      "\n",
      "        Name  Age  Salary  Performance Score\n",
      "0        Ram   28    5000                 43\n",
      "1      Shyam   32    6900                 71\n",
      "2  Ghanshyam   47   45000                 26\n",
      "3  Dhanshyam   57    5200                 59\n",
      "4      Aditi   17    4900                 84\n",
      "5    Jagdish   27    7000                 38\n",
      "6        Raj   77    9000                 67\n",
      "7     Simran   25   17000                 22\n"
     ]
    }
   ],
   "source": [
    "# Updating Shyam's salary (2nd row, index 1)\n",
    "df.loc[1, 'Salary'] = 6900\n",
    "print(\"\\nüìå Updated Salary of Shyam:\\n\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc32b612",
   "metadata": {},
   "source": [
    "## üìà Increasing All Salaries by 5%\n",
    "\n",
    "We can update an entire column using vectorized operations.\n",
    "\n",
    "### üìå Syntax:\n",
    "```python\n",
    "df['Column'] = df['Column'] * multiplier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a68585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí∏ Salary after 5% increment:\n",
      "\n",
      "        Name  Age   Salary  Performance Score\n",
      "0        Ram   28   5250.0                 43\n",
      "1      Shyam   32   7245.0                 71\n",
      "2  Ghanshyam   47  47250.0                 26\n",
      "3  Dhanshyam   57   5460.0                 59\n",
      "4      Aditi   17   5145.0                 84\n",
      "5    Jagdish   27   7350.0                 38\n",
      "6        Raj   77   9450.0                 67\n",
      "7     Simran   25  17850.0                 22\n"
     ]
    }
   ],
   "source": [
    "# Increasing all salaries by 5%\n",
    "df['Salary'] = df['Salary'] * 1.05\n",
    "print(\"\\nüí∏ Salary after 5% increment:\\n\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0b9e2",
   "metadata": {},
   "source": [
    "## ‚ùå Deleting/Removing a Column using `.drop()`\n",
    "\n",
    "To remove unwanted columns, we use the `drop()` method.\n",
    "\n",
    "### üìå Syntax:\n",
    "```python\n",
    "df.drop(columns=['col1', 'col2'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccbcb06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üóëÔ∏è DataFrame after deleting 'Performance Score':\n",
      "\n",
      "        Name  Age   Salary\n",
      "0        Ram   28   5250.0\n",
      "1      Shyam   32   7245.0\n",
      "2  Ghanshyam   47  47250.0\n",
      "3  Dhanshyam   57   5460.0\n",
      "4      Aditi   17   5145.0\n",
      "5    Jagdish   27   7350.0\n",
      "6        Raj   77   9450.0\n",
      "7     Simran   25  17850.0\n"
     ]
    }
   ],
   "source": [
    "# Removing the Performance Score column\n",
    "df.drop(columns=[\"Performance Score\"], inplace=True)\n",
    "print(\"\\nüóëÔ∏è DataFrame after deleting 'Performance Score':\\n\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22dff26",
   "metadata": {},
   "source": [
    "## üß† Summary of Syntax Used\n",
    "\n",
    "| Operation             | Syntax Example                                      |\n",
    "|-----------------------|-----------------------------------------------------|\n",
    "| Update specific cell  | `df.loc[row, 'col'] = value`                        |\n",
    "| Increase column values| `df['col'] = df['col'] * multiplier`               |\n",
    "| Drop columns          | `df.drop(columns=['col1', 'col2'], inplace=True)`  |\n",
    "| Create DataFrame      | `df = pd.DataFrame(data)`                          |\n",
    "\n",
    "These are some of the most common and useful DataFrame operations!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7ff67",
   "metadata": {},
   "source": [
    "# --- End of `Fourth` notebook ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a5d98",
   "metadata": {},
   "source": [
    "# --- Start of `Fifth` notebook ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcefadd",
   "metadata": {},
   "source": [
    "# üßº Handling Missing Data with Pandas\n",
    "\n",
    "In this notebook, we'll cover:\n",
    "- Detecting missing values\n",
    "- Deleting/removing missing data or unwanted columns\n",
    "- Filling missing data with static or computed values\n",
    "- Interpolating missing data using various methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972ba8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Importing pandas\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83627082",
   "metadata": {},
   "source": [
    "## üìä Step 1: Create Sample DataFrame with Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d51a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name   Age   Salary  Performance Score\n",
      "0        Ram  28.0   5000.0               43.0\n",
      "1       None   NaN      NaN                NaN\n",
      "2  Ghanshyam  47.0  45000.0               26.0\n",
      "3  Dhanshyam  57.0   5200.0               59.0\n",
      "4      Aditi  17.0   4900.0               84.0\n",
      "5    Jagdish  27.0   7000.0               38.0\n",
      "6        Raj  77.0   9000.0               67.0\n",
      "7     Simran  25.0  17000.0               22.0\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\": ['Ram', None, 'Ghanshyam', 'Dhanshyam', 'Aditi', 'Jagdish', 'Raj', 'Simran'],\n",
    "    \"Age\": [28, None, 47, 57, 17, 27, 77, 25],\n",
    "    \"Salary\": [5000, None, 45000, 5200, 4900, 7000, 9000, 17000],\n",
    "    \"Performance Score\": [43, None, 26, 59, 84, 38, 67, 22]  \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495de07e",
   "metadata": {},
   "source": [
    "## üîç Step 2: Detect Missing Data\n",
    "\n",
    "- `isnull()` returns a DataFrame of boolean values showing where data is missing.\n",
    "- `isnull().sum()` shows total number of missing values in each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where is data missing?\n",
      "\n",
      "    Name    Age  Salary  Performance Score\n",
      "0  False  False   False              False\n",
      "1   True   True    True               True\n",
      "2  False  False   False              False\n",
      "3  False  False   False              False\n",
      "4  False  False   False              False\n",
      "5  False  False   False              False\n",
      "6  False  False   False              False\n",
      "7  False  False   False              False\n",
      "\n",
      "Total number of missing values per column:\n",
      "\n",
      "Name                 1\n",
      "Age                  1\n",
      "Salary               1\n",
      "Performance Score    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Where is data missing?\\n\")\n",
    "print(df.isnull())\n",
    "\n",
    "print(\"\\nTotal number of missing values per column:\\n\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410a8904",
   "metadata": {},
   "source": [
    "## üßπ Step 3: Remove Missing Data\n",
    "\n",
    "We can remove:\n",
    "- Rows with any missing data using `dropna()`\n",
    "- Columns with missing data using `dropna(axis=1)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cea425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing rows with missing values:\n",
      "\n",
      "        Name   Age   Salary  Performance Score\n",
      "0        Ram  28.0   5000.0               43.0\n",
      "2  Ghanshyam  47.0  45000.0               26.0\n",
      "3  Dhanshyam  57.0   5200.0               59.0\n",
      "4      Aditi  17.0   4900.0               84.0\n",
      "5    Jagdish  27.0   7000.0               38.0\n",
      "6        Raj  77.0   9000.0               67.0\n",
      "7     Simran  25.0  17000.0               22.0\n"
     ]
    }
   ],
   "source": [
    "# Removing rows with any missing values\n",
    "df_removed = df.copy()\n",
    "df_removed.dropna(inplace=True)\n",
    "print(\"After removing rows with missing values:\\n\")\n",
    "print(df_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93672d65",
   "metadata": {},
   "source": [
    "## üß™ Step 4: Fill Missing Data (Imputation)\n",
    "\n",
    "We can use:\n",
    "- A constant value (e.g., 77)\n",
    "- A computed value like mean, median, or mode for specific columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a46e5ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filling missing Age and Salary with their means:\n",
      "\n",
      "        Name        Age   Salary  Performance Score\n",
      "0        Ram  28.000000   5000.0               43.0\n",
      "1       None  39.714286  13300.0                NaN\n",
      "2  Ghanshyam  47.000000  45000.0               26.0\n",
      "3  Dhanshyam  57.000000   5200.0               59.0\n",
      "4      Aditi  17.000000   4900.0               84.0\n",
      "5    Jagdish  27.000000   7000.0               38.0\n",
      "6        Raj  77.000000   9000.0               67.0\n",
      "7     Simran  25.000000  17000.0               22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwwsh\\AppData\\Local\\Temp\\ipykernel_20152\\1415329042.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_filled['Age'].fillna(df_filled['Age'].mean(), inplace=True)\n",
      "C:\\Users\\wwwsh\\AppData\\Local\\Temp\\ipykernel_20152\\1415329042.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_filled['Salary'].fillna(df_filled['Salary'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Filling missing values with appropriate replacements\n",
    "df_filled = pd.DataFrame(data)  # recreate DataFrame\n",
    "\n",
    "# Fill entire DataFrame with constant (optional)\n",
    "# df_filled.fillna(77, inplace=True)\n",
    "\n",
    "# Fill specific columns with mean values\n",
    "df_filled['Age'].fillna(df_filled['Age'].mean(), inplace=True)\n",
    "df_filled['Salary'].fillna(df_filled['Salary'].mean(), inplace=True)\n",
    "\n",
    "print(\"After filling missing Age and Salary with their means:\\n\")\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573e129",
   "metadata": {},
   "source": [
    "# üîÑ Step 5: Interpolation in Pandas\n",
    "\n",
    "Interpolation is a method of estimating missing values between two known values.\n",
    "\n",
    "### Types of Interpolation:\n",
    "\n",
    "1. **Linear**:\n",
    "   - Fills missing values linearly from nearby values.\n",
    "   - Good for numeric trends.\n",
    "   - `method='linear'`\n",
    "\n",
    "2. **Polynomial**:\n",
    "   - Fills using polynomial equations of specified order (e.g., quadratic).\n",
    "   - Can be more accurate but risky if overfitted.\n",
    "   - `method='polynomial', order=n`\n",
    "\n",
    "3. **Time**:\n",
    "   - Interpolates assuming index is datetime.\n",
    "   - Useful for time series data.\n",
    "   - `method='time'` (only works with DateTimeIndex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5d81d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Linear Interpolation:\n",
      "\n",
      "        Name   Age   Salary  Performance Score\n",
      "0        Ram  28.0   5000.0               43.0\n",
      "1       None  37.5  25000.0               34.5\n",
      "2  Ghanshyam  47.0  45000.0               26.0\n",
      "3  Dhanshyam  57.0   5200.0               59.0\n",
      "4      Aditi  17.0   4900.0               84.0\n",
      "5    Jagdish  27.0   7000.0               38.0\n",
      "6        Raj  77.0   9000.0               67.0\n",
      "7     Simran  25.0  17000.0               22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwwsh\\AppData\\Local\\Temp\\ipykernel_20152\\2171245244.py:6: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df_interp_linear.interpolate(method=\"linear\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Recreate original DataFrame\n",
    "df_interp = pd.DataFrame(data)\n",
    "\n",
    "# Interpolate missing values using linear method\n",
    "df_interp_linear = df_interp.copy()\n",
    "df_interp_linear.interpolate(method=\"linear\", inplace=True)\n",
    "\n",
    "print(\"üîó Linear Interpolation:\\n\")\n",
    "print(df_interp_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f894cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwwsh\\AppData\\Local\\Temp\\ipykernel_20152\\1796064651.py:3: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df_interp_poly.interpolate(method=\"polynomial\", order=2, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìê Polynomial Interpolation (order=2):\n",
      "\n",
      "        Name        Age        Salary  Performance Score\n",
      "0        Ram  28.000000   5000.000000          43.000000\n",
      "1       None  33.704057  49565.579422          19.593742\n",
      "2  Ghanshyam  47.000000  45000.000000          26.000000\n",
      "3  Dhanshyam  57.000000   5200.000000          59.000000\n",
      "4      Aditi  17.000000   4900.000000          84.000000\n",
      "5    Jagdish  27.000000   7000.000000          38.000000\n",
      "6        Raj  77.000000   9000.000000          67.000000\n",
      "7     Simran  25.000000  17000.000000          22.000000\n"
     ]
    }
   ],
   "source": [
    "# Polynomial interpolation (order=2)\n",
    "df_interp_poly = pd.DataFrame(data)\n",
    "df_interp_poly.interpolate(method=\"polynomial\", order=2, inplace=True)\n",
    "\n",
    "print(\"üìê Polynomial Interpolation (order=2):\\n\")\n",
    "print(df_interp_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea719d2",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Note on Time Interpolation**\n",
    "\n",
    "`method='time'` only works if your DataFrame has a DateTime index or column. It does **not work** on plain integers or floats.\n",
    "\n",
    "Below is an example showing why it doesn‚Äôt work with just numeric values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae8cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame with missing time:\n",
      "\n",
      "   time  val\n",
      "0   1.0   10\n",
      "1   2.0   20\n",
      "2   NaN   30\n",
      "3   4.0   40\n",
      "4   NaN   50\n",
      "5   7.0   60\n",
      "6   NaN   70\n",
      "7  10.0  100\n",
      "\n",
      "Polynomial Interpolation on 'time':\n",
      "\n",
      "        time  val\n",
      "0   1.000000   10\n",
      "1   2.000000   20\n",
      "2   2.929293   30\n",
      "3   4.000000   40\n",
      "4   5.424242   50\n",
      "5   7.000000   60\n",
      "6   8.525253   70\n",
      "7  10.000000  100\n"
     ]
    }
   ],
   "source": [
    "# Example with numeric column for time\n",
    "data2 = {\n",
    "    \"time\": [1, 2, None, 4, None, 7, None, 10],\n",
    "    \"val\": [10, 20, 30, 40, 50, 60, 70, 100]\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "print(\"Original DataFrame with missing time:\\n\")\n",
    "print(df2)\n",
    "\n",
    "print(\"\\nPolynomial Interpolation on 'time':\\n\")\n",
    "df2[\"time\"] = df2[\"time\"].interpolate(method=\"polynomial\", order=2)\n",
    "print(df2)\n",
    "\n",
    "# Reminder:\n",
    "# df2[\"time\"] = df2[\"time\"].interpolate(method=\"time\")  # ‚ùå Will not work without datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d8a73",
   "metadata": {},
   "source": [
    "# --- End of `Fifth` notebook ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318997cd",
   "metadata": {},
   "source": [
    "# --- Start of `Sixth` notebook ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd3deac",
   "metadata": {},
   "source": [
    "# üìä Sorting, Aggregation & Grouping in Pandas\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Sorting by one or more columns\n",
    "- Aggregation functions (mean, sum, min, max, etc.)\n",
    "- Grouping data with aggregation\n",
    "\n",
    "We'll use pandas to handle tabular data efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e357fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÉ Importing pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ebd4be",
   "metadata": {},
   "source": [
    "## üìã Sample DataFrame\n",
    "\n",
    "This is the sample data we'll use for all our operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86932d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name  Age  Salary  Performance Score\n",
      "0        Ram   28    5000                 43\n",
      "1      Shyam   32    6000                 71\n",
      "2  Ghanshyam   47   45000                 26\n",
      "3  Dhanshyam   57    5200                 59\n",
      "4      Aditi   17    4900                 84\n",
      "5    Jagdish   27    7000                 38\n",
      "6        Raj   77    9000                 67\n",
      "7     Simran   25   17000                 22\n"
     ]
    }
   ],
   "source": [
    "# Creating sample data\n",
    "data = {\n",
    "    \"Name\": ['Ram', 'Shyam', 'Ghanshyam', 'Dhanshyam', 'Aditi', 'Jagdish', 'Raj', 'Simran'],\n",
    "    \"Age\": [28, 32, 47, 57, 17, 27, 77, 25],\n",
    "    \"Salary\": [5000, 6000, 45000, 5200, 4900, 7000, 9000, 17000],\n",
    "    \"Performance Score\": [43, 71, 26, 59, 84, 38, 67, 22]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0649524",
   "metadata": {},
   "source": [
    "## üî¢ Sorting - Single Column\n",
    "\n",
    "Use `df.sort_values(by=\"column_name\", ascending=True/False, inplace=True)`\n",
    "\n",
    "- `ascending=True` ‚Üí Ascending order\n",
    "- `ascending=False` ‚Üí Descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f7dc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå After Sorting by Name (ascending):\n",
      "        Name  Age  Salary  Performance Score\n",
      "4      Aditi   17    4900                 84\n",
      "3  Dhanshyam   57    5200                 59\n",
      "2  Ghanshyam   47   45000                 26\n",
      "5    Jagdish   27    7000                 38\n",
      "6        Raj   77    9000                 67\n",
      "0        Ram   28    5000                 43\n",
      "1      Shyam   32    6000                 71\n",
      "7     Simran   25   17000                 22\n"
     ]
    }
   ],
   "source": [
    "# Sort by Name (ascending)\n",
    "df.sort_values(by=\"Name\", ascending=True, inplace=True)\n",
    "print(\"üìå After Sorting by Name (ascending):\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d97cb33",
   "metadata": {},
   "source": [
    "## üî¢ Sorting - Multiple Columns\n",
    "\n",
    "Syntax:\n",
    "```python\n",
    "df.sort_values(by=[\"col1\", \"col2\"], ascending=[True, False], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab3baebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå After Sorting by Age and Salary:\n",
      "        Name  Age  Salary  Performance Score\n",
      "4      Aditi   17    4900                 84\n",
      "7     Simran   25   17000                 22\n",
      "5    Jagdish   27    7000                 38\n",
      "0        Ram   28    5000                 43\n",
      "1      Shyam   32    6000                 71\n",
      "2  Ghanshyam   47   45000                 26\n",
      "3  Dhanshyam   57    5200                 59\n",
      "6        Raj   77    9000                 67\n"
     ]
    }
   ],
   "source": [
    "# Recreating DataFrame for fresh sort\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sort by Age first, then Salary\n",
    "df.sort_values(by=[\"Age\", \"Salary\"], ascending=[True, True], inplace=True)\n",
    "print(\"üìå After Sorting by Age and Salary:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd44ff49",
   "metadata": {},
   "source": [
    "## üìà Aggregation Functions\n",
    "\n",
    "We can use the following functions on a column:\n",
    "- `df[\"Column\"].mean()` ‚Üí Average\n",
    "- `df[\"Column\"].sum()` ‚Üí Total\n",
    "- `df[\"Column\"].min()` ‚Üí Minimum\n",
    "- `df[\"Column\"].max()` ‚Üí Maximum\n",
    "- `df[\"Column\"].std()` ‚Üí Standard Deviation\n",
    "- `df[\"Column\"].count()` ‚Üí Count of non-null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89859024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Aggregation on Age column:\n",
      "Mean: 38.75\n",
      "Sum: 310\n",
      "Min: 17\n",
      "Max: 77\n",
      "Std Dev: 20.090865017287264\n",
      "Count: 8\n"
     ]
    }
   ],
   "source": [
    "# Aggregation Examples on Age column\n",
    "print(\"üìä Aggregation on Age column:\")\n",
    "print(\"Mean:\", df[\"Age\"].mean())\n",
    "print(\"Sum:\", df[\"Age\"].sum())\n",
    "print(\"Min:\", df[\"Age\"].min())\n",
    "print(\"Max:\", df[\"Age\"].max())\n",
    "print(\"Std Dev:\", df[\"Age\"].std())\n",
    "print(\"Count:\", df[\"Age\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b957b08",
   "metadata": {},
   "source": [
    "## üë• Grouping and Aggregation\n",
    "\n",
    "### ‚û§ Group by Single Column\n",
    "Syntax:\n",
    "```python\n",
    "df.groupby(\"column\")[\"target_column\"].aggregation_function()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6313ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Grouped by Age (Total Salary):\n",
      "Age\n",
      "17     4900\n",
      "25    17000\n",
      "27     7000\n",
      "28     5000\n",
      "32     6000\n",
      "47    45000\n",
      "57     5200\n",
      "77     9000\n",
      "Name: Salary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group by Age and calculate total Salary\n",
    "group1 = df.groupby(\"Age\")[\"Salary\"].sum()\n",
    "print(\"üìå Grouped by Age (Total Salary):\")\n",
    "print(group1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1728ea",
   "metadata": {},
   "source": [
    "# --- End of `Sixth` notebook ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb4120f",
   "metadata": {},
   "source": [
    "# --- Start of `Seventh` notebook ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c31db53",
   "metadata": {},
   "source": [
    "# üîó Merging, Joining, Concatenation and Cross Join in Pandas\n",
    "\n",
    "In this notebook, we'll cover:\n",
    "\n",
    "- Merge and join using different `how` methods\n",
    "- Cross join\n",
    "- Concatenation (vertical and horizontal stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3cac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510594d9",
   "metadata": {},
   "source": [
    "## üîÑ Merge and Join in Pandas\n",
    "\n",
    "We can merge DataFrames based on a common key using:\n",
    "\n",
    "```python\n",
    "pd.merge(df1, df2, on='common_col', how='type')\n",
    "on: column name used as key (common in both)\n",
    "\n",
    "how: type of join: inner, outer, left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d5c3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "   id   name\n",
      "0   1    Ram\n",
      "1   2  Shyam\n",
      "2   3  Geeta\n",
      "3   4   Sita\n",
      "4   5   Ravi\n",
      "5   6   Neha\n",
      "6   7   Amit\n",
      "\n",
      "DataFrame 2:\n",
      "   id  amount\n",
      "0   1     250\n",
      "1   2     400\n",
      "2   3     150\n",
      "3   4     600\n",
      "4   6     500\n",
      "5   7     450\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'name': ['Ram', 'Shyam', 'Geeta', 'Sita', 'Ravi', 'Neha', 'Amit']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 6, 7],  # \"id\" 5 is missing here\n",
    "    'amount': [250, 400, 150, 600, 500, 450]\n",
    "})\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82afac04",
   "metadata": {},
   "source": [
    "## üîÅ Inner Join\n",
    "\n",
    "Only keeps rows where the `id` is present in **both** `df1` and `df2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4db5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Inner Join:\n",
      "   id   name  amount\n",
      "0   1    Ram     250\n",
      "1   2  Shyam     400\n",
      "2   3  Geeta     150\n",
      "3   4   Sita     600\n",
      "4   6   Neha     500\n",
      "5   7   Amit     450\n"
     ]
    }
   ],
   "source": [
    "inner_join = pd.merge(df1, df2, on=\"id\", how=\"inner\")\n",
    "print(\"üîó Inner Join:\")\n",
    "print(inner_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aac53b",
   "metadata": {},
   "source": [
    "## üåê Outer Join\n",
    "Keeps **all rows** from both DataFrames. Fills with `NaN` where data is missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd490aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Outer Join:\n",
      "   id   name  amount\n",
      "0   1    Ram   250.0\n",
      "1   2  Shyam   400.0\n",
      "2   3  Geeta   150.0\n",
      "3   4   Sita   600.0\n",
      "4   5   Ravi     NaN\n",
      "5   6   Neha   500.0\n",
      "6   7   Amit   450.0\n"
     ]
    }
   ],
   "source": [
    "outer_join = pd.merge(df1, df2, on=\"id\", how=\"outer\")\n",
    "print(\"üåê Outer Join:\")\n",
    "print(outer_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090540eb",
   "metadata": {},
   "source": [
    "## ‚¨ÖÔ∏è Left Join\n",
    "\n",
    "Keeps **all rows from df1**, and matches from df2 where possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f2dead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨ÖÔ∏è Left Join:\n",
      "   id   name  amount\n",
      "0   1    Ram   250.0\n",
      "1   2  Shyam   400.0\n",
      "2   3  Geeta   150.0\n",
      "3   4   Sita   600.0\n",
      "4   5   Ravi     NaN\n",
      "5   6   Neha   500.0\n",
      "6   7   Amit   450.0\n"
     ]
    }
   ],
   "source": [
    "left_join = pd.merge(df1, df2, on=\"id\", how=\"left\")\n",
    "print(\"‚¨ÖÔ∏è Left Join:\")\n",
    "print(left_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae1918e",
   "metadata": {},
   "source": [
    "## ‚û°Ô∏è Right Join\n",
    "\n",
    "Keeps **all rows from df2**, and matches from df1 where possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a8bd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚û°Ô∏è Right Join:\n",
      "   id   name  amount\n",
      "0   1    Ram     250\n",
      "1   2  Shyam     400\n",
      "2   3  Geeta     150\n",
      "3   4   Sita     600\n",
      "4   6   Neha     500\n",
      "5   7   Amit     450\n"
     ]
    }
   ],
   "source": [
    "right_join = pd.merge(df1, df2, on=\"id\", how=\"right\")\n",
    "print(\"‚û°Ô∏è Right Join:\")\n",
    "print(right_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fd2963",
   "metadata": {},
   "source": [
    "## üîÄ Cross Join\n",
    "\n",
    "Combines every row of `df1` with every row of `df2`.\n",
    "\n",
    "üß† Cartesian Product: if df1 has `m` rows and df2 has `n` rows, result = `m * n` rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19e099b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÄ Cross Join (Cartesian Product):\n",
      "    id_x   name  id_y  amount\n",
      "0      1    Ram     1     250\n",
      "1      1    Ram     2     400\n",
      "2      1    Ram     3     150\n",
      "3      1    Ram     4     600\n",
      "4      1    Ram     6     500\n",
      "5      1    Ram     7     450\n",
      "6      2  Shyam     1     250\n",
      "7      2  Shyam     2     400\n",
      "8      2  Shyam     3     150\n",
      "9      2  Shyam     4     600\n",
      "10     2  Shyam     6     500\n",
      "11     2  Shyam     7     450\n",
      "12     3  Geeta     1     250\n",
      "13     3  Geeta     2     400\n",
      "14     3  Geeta     3     150\n",
      "15     3  Geeta     4     600\n",
      "16     3  Geeta     6     500\n",
      "17     3  Geeta     7     450\n",
      "18     4   Sita     1     250\n",
      "19     4   Sita     2     400\n",
      "20     4   Sita     3     150\n",
      "21     4   Sita     4     600\n",
      "22     4   Sita     6     500\n",
      "23     4   Sita     7     450\n",
      "24     5   Ravi     1     250\n",
      "25     5   Ravi     2     400\n",
      "26     5   Ravi     3     150\n",
      "27     5   Ravi     4     600\n",
      "28     5   Ravi     6     500\n",
      "29     5   Ravi     7     450\n",
      "30     6   Neha     1     250\n",
      "31     6   Neha     2     400\n",
      "32     6   Neha     3     150\n",
      "33     6   Neha     4     600\n",
      "34     6   Neha     6     500\n",
      "35     6   Neha     7     450\n",
      "36     7   Amit     1     250\n",
      "37     7   Amit     2     400\n",
      "38     7   Amit     3     150\n",
      "39     7   Amit     4     600\n",
      "40     7   Amit     6     500\n",
      "41     7   Amit     7     450\n"
     ]
    }
   ],
   "source": [
    "# Enabling cross join by adding dummy key to both\n",
    "df1_cross = df1.copy()\n",
    "df2_cross = df2.copy()\n",
    "df1_cross['key'] = 1\n",
    "df2_cross['key'] = 1\n",
    "\n",
    "cross_join = pd.merge(df1_cross, df2_cross, on='key').drop('key', axis=1)\n",
    "print(\"üîÄ Cross Join (Cartesian Product):\")\n",
    "print(cross_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e25ba20",
   "metadata": {},
   "source": [
    "# üìö Concatenation\n",
    "\n",
    "We can concatenate DataFrames:\n",
    "- **Vertically (row-wise)** using `axis=0`\n",
    "- **Horizontally (column-wise)** using `axis=1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175b3b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Vertical Concatenation:\n",
      "   id    nam\n",
      "0   1   Raju\n",
      "1   2  Rajiv\n",
      "2   3   Isha\n",
      "3   4  Ishan\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"id\": [1, 2],\n",
    "    \"nam\": [\"Raju\", \"Rajiv\"]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    \"id\": [3, 4],\n",
    "    \"nam\": [\"Isha\", \"Ishan\"]\n",
    "})\n",
    "\n",
    "# üß± Vertical Concatenation\n",
    "vertical_concat = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "print(\"‚¨áÔ∏è Vertical Concatenation:\")\n",
    "print(vertical_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bc943c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚û°Ô∏è Horizontal Concatenation:\n",
      "   id    nam  id    nam\n",
      "0   1   Raju   3   Isha\n",
      "1   2  Rajiv   4  Ishan\n"
     ]
    }
   ],
   "source": [
    "# üß± Horizontal Concatenation\n",
    "horizontal_concat = pd.concat([df1, df2], axis=1)\n",
    "print(\"‚û°Ô∏è Horizontal Concatenation:\")\n",
    "print(horizontal_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe2793",
   "metadata": {},
   "source": [
    "# --- End of `Seventh` notebook ---\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
